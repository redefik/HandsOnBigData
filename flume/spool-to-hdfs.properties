# Obiettivo vogliamo fare ingestion da una spooling directory verso l'HDFS
# Il file è mantenuto aperto dall'HDFS finché non si verifica uno dei seguenti eventi:
# - E' rimasto aperto per un certo tempo (default 30 secondi)
#   hdfs.rollInterval
# - Sono stati scritti al suo interno un certo numero di eventi (10 per default)
#   hdfs.rollCount
# - Ha raggiunto una certa dimensione (default 1024 B)
#   hdfs.rollSize 
# Se una di queste condizioni è verificata, il file viene chieso, vengono rimossi eventuali prefissi e suffissi e i nuovi eventi saranno scritti su un altro file.

agent1.sources=source1
agent1.sinks=sink1
agent1.channels=channel1

agent1.sources.source1.channels=channel1
agent1.sinks.sink1.channel=channel1

agent1.sources.source1.type=spooldir
agent1.sources.source1.spoolDir=/tmp/spooldir

# PROPERTY OBBLIGATORIE
# Nuovo tipo di sink
agent1.sinks.sink1.type=hdfs
# Directory dove vengono salvati i file
agent1.sinks.sink1.hdfs.path=/tmp/flume

# PROPERTY NON OBBLIGATORIE
agent1.sinks.sink1.hdfs.filePrefix=events
agent1.sinks.sink1.hdfs.fileSuffix=.log
agent1.sinks.sink1.hdfs.inUsePrefix=_
# DataStream è per plain text
agent1.sinks.sink1.hdfs.fileType=DataStream

agent1.channels.channel1.type=file

# Può essere necessario rimuovere il .jar di guava per far funzionare l'ingestion
